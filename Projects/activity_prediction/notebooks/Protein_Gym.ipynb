{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd4c9b2-ff73-4e56-aec9-b016e656f7de",
   "metadata": {},
   "source": [
    "# Data preparation for ML pipeline\n",
    "---\n",
    "In this script I am preparing datasets for my machine learning pipeline. My objective is to train machine learning models for the prediction of variant effects, that are either family agnostic or family aware. The family agnostic models will be trained on the wt sequence and the sequence variants alone, while the family aware models will additionally be trained on MSA for the protein of interest.\n",
    "\n",
    "The proteins I will be analyzing have been tested using deep mutational scanning experiments and were curated and collected in the [ProteinGym](https://github.com/OATML-Markslab/ProteinGym) by the [OATML](https://oatml.cs.ox.ac.uk/) research group.\n",
    "\n",
    "Personally I am intersted in prediction the effects of mutations on enzyme activity, therefore I will be filtering the data for DMS experiments which either directly or indirectly measured the enzyme activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490d9e7e-d509-49c8-81d1-d4ba65c042fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "import proteusAI.io_tools as io_tools\n",
    "import proteusAI.data_tools as data_tools\n",
    "import proteusAI.ml_tools.esm_tools as esm_tools\n",
    "import proteusAI.ml_tools.torch_tools as torch_tools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import optim\n",
    "\n",
    "protein_gym_path = '../../example_data/ProteinGym_substitutions/'\n",
    "metadata = pd.read_csv('../../example_data/ProteinGym_reference_file_substitutions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592bacf3-2faf-46b0-9085-c17fce991fbc",
   "metadata": {},
   "source": [
    "## Collect all studies related to enzyme activity and move them to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957830e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMS_id</th>\n",
       "      <th>DMS_filename</th>\n",
       "      <th>UniProt_ID</th>\n",
       "      <th>taxon</th>\n",
       "      <th>target_seq</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>includes_multiple_mutants</th>\n",
       "      <th>DMS_total_number_mutants</th>\n",
       "      <th>DMS_number_single_mutants</th>\n",
       "      <th>DMS_number_multiple_mutants</th>\n",
       "      <th>...</th>\n",
       "      <th>MSA_N_eff</th>\n",
       "      <th>MSA_Neff_L</th>\n",
       "      <th>MSA_Neff_L_category</th>\n",
       "      <th>MSA_num_significant</th>\n",
       "      <th>MSA_num_significant_L</th>\n",
       "      <th>raw_DMS_filename</th>\n",
       "      <th>raw_DMS_phenotype_name</th>\n",
       "      <th>raw_DMS_directionality</th>\n",
       "      <th>raw_DMS_mutant_column</th>\n",
       "      <th>weight_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AMIE_PSEAE_Wrenbeck_2017</td>\n",
       "      <td>AMIE_PSEAE_Wrenbeck_2017.csv</td>\n",
       "      <td>AMIE_PSEAE</td>\n",
       "      <td>Prokaryote</td>\n",
       "      <td>MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...</td>\n",
       "      <td>346</td>\n",
       "      <td>False</td>\n",
       "      <td>6227</td>\n",
       "      <td>6227</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29959.3</td>\n",
       "      <td>119.359761</td>\n",
       "      <td>high</td>\n",
       "      <td>557</td>\n",
       "      <td>2.219124</td>\n",
       "      <td>AMIE_PSEAE_Wrenbeck_2017.csv</td>\n",
       "      <td>isobutyramide_normalized_fitness</td>\n",
       "      <td>1</td>\n",
       "      <td>mutant</td>\n",
       "      <td>AMIE_PSEAE_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CCDB_ECOLI_Tripathi_2016</td>\n",
       "      <td>CCDB_ECOLI_Tripathi_2016.csv</td>\n",
       "      <td>CCDB_ECOLI</td>\n",
       "      <td>Prokaryote</td>\n",
       "      <td>MQFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16821.5</td>\n",
       "      <td>195.598837</td>\n",
       "      <td>high</td>\n",
       "      <td>61</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>CCDB_ECOLI_Tripathi_2016.csv</td>\n",
       "      <td>score</td>\n",
       "      <td>-1</td>\n",
       "      <td>mutant</td>\n",
       "      <td>CCDB_ECOLI_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CP2C9_HUMAN_Amorosi_abundance_2021</td>\n",
       "      <td>CP2C9_HUMAN_Amorosi_abundance_2021.csv</td>\n",
       "      <td>CP2C9_HUMAN</td>\n",
       "      <td>Human</td>\n",
       "      <td>MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...</td>\n",
       "      <td>490</td>\n",
       "      <td>False</td>\n",
       "      <td>6370</td>\n",
       "      <td>6370</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81212.1</td>\n",
       "      <td>187.124654</td>\n",
       "      <td>high</td>\n",
       "      <td>1092</td>\n",
       "      <td>2.516129</td>\n",
       "      <td>CP2C9_HUMAN_Amorosi_2021.csv</td>\n",
       "      <td>abundance_score</td>\n",
       "      <td>1</td>\n",
       "      <td>variant</td>\n",
       "      <td>CP2C9_HUMAN_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CP2C9_HUMAN_Amorosi_activity_2021</td>\n",
       "      <td>CP2C9_HUMAN_Amorosi_activity_2021.csv</td>\n",
       "      <td>CP2C9_HUMAN</td>\n",
       "      <td>Human</td>\n",
       "      <td>MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...</td>\n",
       "      <td>490</td>\n",
       "      <td>False</td>\n",
       "      <td>6142</td>\n",
       "      <td>6142</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81212.1</td>\n",
       "      <td>187.124654</td>\n",
       "      <td>high</td>\n",
       "      <td>1092</td>\n",
       "      <td>2.516129</td>\n",
       "      <td>CP2C9_HUMAN_Amorosi_2021.csv</td>\n",
       "      <td>activity_score</td>\n",
       "      <td>1</td>\n",
       "      <td>variant</td>\n",
       "      <td>CP2C9_HUMAN_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>MSH2_HUMAN_Jia_2020</td>\n",
       "      <td>MSH2_HUMAN_Jia_2020.csv</td>\n",
       "      <td>MSH2_HUMAN</td>\n",
       "      <td>Human</td>\n",
       "      <td>MAVQPKETLQLESAAEVGFVRFFQGMPEKPTTTVRLFDRGDFYTAH...</td>\n",
       "      <td>934</td>\n",
       "      <td>False</td>\n",
       "      <td>16749</td>\n",
       "      <td>16749</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10716.4</td>\n",
       "      <td>12.727316</td>\n",
       "      <td>medium</td>\n",
       "      <td>1035</td>\n",
       "      <td>1.229216</td>\n",
       "      <td>MSH2_HUMAN_Jia_2020.csv</td>\n",
       "      <td>LOF score</td>\n",
       "      <td>-1</td>\n",
       "      <td>Variant</td>\n",
       "      <td>MSH2_HUMAN_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>PTEN_HUMAN_Mighell_2018</td>\n",
       "      <td>PTEN_HUMAN_Mighell_2018.csv</td>\n",
       "      <td>PTEN_HUMAN</td>\n",
       "      <td>Human</td>\n",
       "      <td>MTAIIKEIVSRNKRRYQEDGFDLDLTYIYPNIIAMGFPAERLEGVY...</td>\n",
       "      <td>403</td>\n",
       "      <td>False</td>\n",
       "      <td>7260</td>\n",
       "      <td>7260</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1425.3</td>\n",
       "      <td>4.703960</td>\n",
       "      <td>medium</td>\n",
       "      <td>52</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>PTEN_HUMAN_Mighell_2018.csv</td>\n",
       "      <td>Fitness_score</td>\n",
       "      <td>1</td>\n",
       "      <td>mutant</td>\n",
       "      <td>PTEN_HUMAN_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Q59976_STRSQ_Romero_2015</td>\n",
       "      <td>Q59976_STRSQ_Romero_2015.csv</td>\n",
       "      <td>Q59976_STRSQ</td>\n",
       "      <td>Prokaryote</td>\n",
       "      <td>MVPAAQQTAMAPDAALTFPEGFLWGSATASYQIEGAAAEDGRTPSI...</td>\n",
       "      <td>501</td>\n",
       "      <td>False</td>\n",
       "      <td>2999</td>\n",
       "      <td>2999</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13981.2</td>\n",
       "      <td>31.631674</td>\n",
       "      <td>medium</td>\n",
       "      <td>850</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>Q59976_STRSQ_Romero_2015.csv</td>\n",
       "      <td>enrichment</td>\n",
       "      <td>1</td>\n",
       "      <td>mutant</td>\n",
       "      <td>Q59976_STRSQ_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RL401_YEAST_Roscoe_2014</td>\n",
       "      <td>RL401_YEAST_Roscoe_2014.csv</td>\n",
       "      <td>RL40A_YEAST</td>\n",
       "      <td>Eukaryote</td>\n",
       "      <td>MQIFVKTLTGKTITLEVESSDTIDNVKSKIQDKEGIPPDQQRLIFA...</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>1380</td>\n",
       "      <td>1380</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3974.4</td>\n",
       "      <td>44.656180</td>\n",
       "      <td>medium</td>\n",
       "      <td>12</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>RL401_YEAST_Roscoe_2014.csv</td>\n",
       "      <td>rel_react</td>\n",
       "      <td>1</td>\n",
       "      <td>mutant</td>\n",
       "      <td>RL401_YEAST_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SRC_HUMAN_Ahler_CD_2019</td>\n",
       "      <td>SRC_HUMAN_Ahler_CD_2019.csv</td>\n",
       "      <td>SRC_HUMAN</td>\n",
       "      <td>Human</td>\n",
       "      <td>MGSNKSKPKDASQRRRSLEPAENVHGAGGGAFPASQTPSKPASADG...</td>\n",
       "      <td>536</td>\n",
       "      <td>False</td>\n",
       "      <td>3372</td>\n",
       "      <td>3372</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1405.1</td>\n",
       "      <td>3.245035</td>\n",
       "      <td>medium</td>\n",
       "      <td>86</td>\n",
       "      <td>0.198614</td>\n",
       "      <td>SRC_HUMAN_Ahler_CD_2019.csv</td>\n",
       "      <td>Activity_Score</td>\n",
       "      <td>1</td>\n",
       "      <td>mutant_uniprot_1</td>\n",
       "      <td>SRC_HUMAN_theta_0.2.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DMS_id  \\\n",
       "10            AMIE_PSEAE_Wrenbeck_2017   \n",
       "21            CCDB_ECOLI_Tripathi_2016   \n",
       "22  CP2C9_HUMAN_Amorosi_abundance_2021   \n",
       "23   CP2C9_HUMAN_Amorosi_activity_2021   \n",
       "43                 MSH2_HUMAN_Jia_2020   \n",
       "58             PTEN_HUMAN_Mighell_2018   \n",
       "60            Q59976_STRSQ_Romero_2015   \n",
       "66             RL401_YEAST_Roscoe_2014   \n",
       "72             SRC_HUMAN_Ahler_CD_2019   \n",
       "\n",
       "                              DMS_filename    UniProt_ID       taxon  \\\n",
       "10            AMIE_PSEAE_Wrenbeck_2017.csv    AMIE_PSEAE  Prokaryote   \n",
       "21            CCDB_ECOLI_Tripathi_2016.csv    CCDB_ECOLI  Prokaryote   \n",
       "22  CP2C9_HUMAN_Amorosi_abundance_2021.csv   CP2C9_HUMAN       Human   \n",
       "23   CP2C9_HUMAN_Amorosi_activity_2021.csv   CP2C9_HUMAN       Human   \n",
       "43                 MSH2_HUMAN_Jia_2020.csv    MSH2_HUMAN       Human   \n",
       "58             PTEN_HUMAN_Mighell_2018.csv    PTEN_HUMAN       Human   \n",
       "60            Q59976_STRSQ_Romero_2015.csv  Q59976_STRSQ  Prokaryote   \n",
       "66             RL401_YEAST_Roscoe_2014.csv   RL40A_YEAST   Eukaryote   \n",
       "72             SRC_HUMAN_Ahler_CD_2019.csv     SRC_HUMAN       Human   \n",
       "\n",
       "                                           target_seq  seq_len  \\\n",
       "10  MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...      346   \n",
       "21  MQFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...      101   \n",
       "22  MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...      490   \n",
       "23  MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...      490   \n",
       "43  MAVQPKETLQLESAAEVGFVRFFQGMPEKPTTTVRLFDRGDFYTAH...      934   \n",
       "58  MTAIIKEIVSRNKRRYQEDGFDLDLTYIYPNIIAMGFPAERLEGVY...      403   \n",
       "60  MVPAAQQTAMAPDAALTFPEGFLWGSATASYQIEGAAAEDGRTPSI...      501   \n",
       "66  MQIFVKTLTGKTITLEVESSDTIDNVKSKIQDKEGIPPDQQRLIFA...      128   \n",
       "72  MGSNKSKPKDASQRRRSLEPAENVHGAGGGAFPASQTPSKPASADG...      536   \n",
       "\n",
       "    includes_multiple_mutants  DMS_total_number_mutants  \\\n",
       "10                      False                      6227   \n",
       "21                      False                      1663   \n",
       "22                      False                      6370   \n",
       "23                      False                      6142   \n",
       "43                      False                     16749   \n",
       "58                      False                      7260   \n",
       "60                      False                      2999   \n",
       "66                      False                      1380   \n",
       "72                      False                      3372   \n",
       "\n",
       "    DMS_number_single_mutants  DMS_number_multiple_mutants  ...  MSA_N_eff  \\\n",
       "10                       6227                            0  ...    29959.3   \n",
       "21                       1663                            0  ...    16821.5   \n",
       "22                       6370                            0  ...    81212.1   \n",
       "23                       6142                            0  ...    81212.1   \n",
       "43                      16749                            0  ...    10716.4   \n",
       "58                       7260                            0  ...     1425.3   \n",
       "60                       2999                            0  ...    13981.2   \n",
       "66                       1380                            0  ...     3974.4   \n",
       "72                       3372                            0  ...     1405.1   \n",
       "\n",
       "    MSA_Neff_L MSA_Neff_L_category MSA_num_significant  MSA_num_significant_L  \\\n",
       "10  119.359761                high                 557               2.219124   \n",
       "21  195.598837                high                  61               0.709302   \n",
       "22  187.124654                high                1092               2.516129   \n",
       "23  187.124654                high                1092               2.516129   \n",
       "43   12.727316              medium                1035               1.229216   \n",
       "58    4.703960              medium                  52               0.171617   \n",
       "60   31.631674              medium                 850               1.923077   \n",
       "66   44.656180              medium                  12               0.134831   \n",
       "72    3.245035              medium                  86               0.198614   \n",
       "\n",
       "                raw_DMS_filename            raw_DMS_phenotype_name  \\\n",
       "10  AMIE_PSEAE_Wrenbeck_2017.csv  isobutyramide_normalized_fitness   \n",
       "21  CCDB_ECOLI_Tripathi_2016.csv                             score   \n",
       "22  CP2C9_HUMAN_Amorosi_2021.csv                   abundance_score   \n",
       "23  CP2C9_HUMAN_Amorosi_2021.csv                    activity_score   \n",
       "43       MSH2_HUMAN_Jia_2020.csv                         LOF score   \n",
       "58   PTEN_HUMAN_Mighell_2018.csv                     Fitness_score   \n",
       "60  Q59976_STRSQ_Romero_2015.csv                        enrichment   \n",
       "66   RL401_YEAST_Roscoe_2014.csv                         rel_react   \n",
       "72   SRC_HUMAN_Ahler_CD_2019.csv                    Activity_Score   \n",
       "\n",
       "   raw_DMS_directionality raw_DMS_mutant_column            weight_file_name  \n",
       "10                      1                mutant    AMIE_PSEAE_theta_0.2.npy  \n",
       "21                     -1                mutant    CCDB_ECOLI_theta_0.2.npy  \n",
       "22                      1               variant   CP2C9_HUMAN_theta_0.2.npy  \n",
       "23                      1               variant   CP2C9_HUMAN_theta_0.2.npy  \n",
       "43                     -1               Variant    MSH2_HUMAN_theta_0.2.npy  \n",
       "58                      1                mutant    PTEN_HUMAN_theta_0.2.npy  \n",
       "60                      1                mutant  Q59976_STRSQ_theta_0.2.npy  \n",
       "66                      1                mutant   RL401_YEAST_theta_0.2.npy  \n",
       "72                      1      mutant_uniprot_1     SRC_HUMAN_theta_0.2.npy  \n",
       "\n",
       "[9 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzyme_data = metadata[metadata['selection_assay'].str.contains('Enzyme function|activity', case=False, na=False)]\n",
    "enzyme_data = enzyme_data[enzyme_data['seq_len'] < 1024]\n",
    "enzyme_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d33c56e-3c98-499b-9696-6a58105f8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_data.to_csv('../enzyme_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73498c58-bd37-4c30-a568-737b2c8719c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_datasets = [f for f in os.listdir('../../example_data/ProteinGym_substitutions/') if f.split('.')[0] in enzyme_data['DMS_id'].to_list()]\n",
    "\n",
    "for f in mutant_datasets:\n",
    "    source_file = os.path.join('../../example_data/ProteinGym_substitutions/', f)\n",
    "    destination_dir = os.path.join('../datasets/', f)\n",
    "    shutil.copy(source_file, destination_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08965523-f981-459d-b391-d93ebcbf292d",
   "metadata": {},
   "source": [
    "## normalize scores between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f18a8895-8a06-4c05-a955-7d3406541177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming dfs is your list of dataframes\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for i, name in enumerate(mutant_datasets):\n",
    "    # load dataset\n",
    "    df = pd.read_csv(f\"../datasets/{name}\")\n",
    "    \n",
    "    # Scale 'DMS_score' and store in 'y'\n",
    "    df['y'] = scaler.fit_transform(df[['DMS_score']])\n",
    "    \n",
    "    # Save the dataframe with the same name at the same location\n",
    "    df.to_csv(f\"../datasets/{name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2340e91f-5a68-4917-9827-9a051df5d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = enzyme_data['target_seq'].to_list()\n",
    "names = enzyme_data['UniProt_ID'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571a7e61-1d8a-482a-a1d6-ee468914eab5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BLAST and MSA\n",
    "---\n",
    "The multiple sequence alignment for the family aware methods will be created from a BLAST search of the individual proteins using the UniRef 100 database as a reference database. The enzymes.fasta file is the uploaded on the [UniProt BLAST](https://www.uniprot.org/blast) tool as input. Blasting using python is to slow, due to the disencouragment of autonomous agents. Sequences found in the BLAST result will be parsed and a MSA alignment will be created using the muscle app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a92ee1-cdef-48c6-b7ef-64e07beca158",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_tools.write_fasta(names, seqs, dest='../../example_data/ProteinGym_substitutions/enzymes.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0970aac7-c8bd-4785-b523-0ac717003d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_blast_output(blast_output_file, identity_threshold=100):\n",
    "    with open(blast_output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sequences = {}\n",
    "    current_id = ''\n",
    "    current_seq = ''\n",
    "    current_identity = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if current_id and current_identity <= identity_threshold:  # if not the first sequence and identity is below threshold\n",
    "                sequences[f\"{current_id}_{current_identity}%\"] = ''.join([aa for aa in current_seq if aa in 'ACDEFGHIKLMNPQRSTVWY'])\n",
    "            current_id = line.split(' ')[0][1:]  # remove '>' and get id\n",
    "            current_seq = ''\n",
    "            current_identity = 0\n",
    "        elif line.startswith(' Identities = '):\n",
    "            current_identity = float(line.split(\",\")[0].split(\"(\")[1].split(\"%\")[0])\n",
    "        elif line.startswith('Sbjct'):\n",
    "            current_seq += line.split()[2]  # append sequence part\n",
    "    # add last sequence\n",
    "    if current_id and current_identity <= identity_threshold:  # if there was at least one sequence and identity is below threshold\n",
    "        sequences[f\"{current_id}_{current_identity}%\"] = ''.join([aa for aa in current_seq if aa in 'ACDEFGHIKLMNPQRSTVWY'])\n",
    "\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46d8046-7591-471e-ae9f-b7df4f282b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_results = {}\n",
    "for name in names:\n",
    "    msa_results[name] = parse_blast_output(f'../../example_data/MSA/{name}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3484ed-a2bb-42f2-8355-f5bd96c1decf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(names)):\n",
    "    _names = [names[i]]\n",
    "    _seqs = [seqs[i]]\n",
    "    break\n",
    "    try:\n",
    "        for name, seq in msa_results[names[i]].items():\n",
    "            _names.append(name)\n",
    "            _seqs.append(seq)\n",
    "        data_tools.align_proteins(_names, _seqs, save_fasta=f'../../example_data/MSA/{names[i]}.fasta', plot_results=False)\n",
    "    except:\n",
    "        n = [names[i]]\n",
    "        seq = [seqs[i]]\n",
    "        io_tools.write_fasta(n, seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41244aa3-bf85-4652-b0d4-34f4bb37d147",
   "metadata": {},
   "source": [
    "## MSA to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf35785f-cebe-40e2-823c-3f25eec4df9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msa_results = io_tools.load_all_fastas('../../example_data/MSA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e070d3-90d8-4a54-b16d-d231bce8c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = msa_results.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d2a86f-3829-4a81-9d17-45ad9e6a7454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSH2_HUMAN</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UR100:UniRef100_P43246_100.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UR100:UniRef100_G3QW00_99.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UR100:UniRef100_A0A8I3B3M9_99.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UR100:UniRef100_UPI0015619230_99.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>UR100:UniRef100_UPI001C69C888_96.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>UR100:UniRef100_A0A8D0V6L8_91.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>UR100:UniRef100_F1SQH6_96.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>UR100:UniRef100_A0A8D1RBY7_96.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>UR100:UniRef100_A0A8C6D0F4_94.0%</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   label  \\\n",
       "0                             MSH2_HUMAN   \n",
       "1          UR100:UniRef100_P43246_100.0%   \n",
       "2           UR100:UniRef100_G3QW00_99.0%   \n",
       "3       UR100:UniRef100_A0A8I3B3M9_99.0%   \n",
       "4    UR100:UniRef100_UPI0015619230_99.0%   \n",
       "..                                   ...   \n",
       "246  UR100:UniRef100_UPI001C69C888_96.0%   \n",
       "247     UR100:UniRef100_A0A8D0V6L8_91.0%   \n",
       "248         UR100:UniRef100_F1SQH6_96.0%   \n",
       "249     UR100:UniRef100_A0A8D1RBY7_96.0%   \n",
       "250     UR100:UniRef100_A0A8C6D0F4_94.0%   \n",
       "\n",
       "                                                     x  \n",
       "0    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "1    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "2    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "3    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "4    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "..                                                 ...  \n",
       "246  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "247  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "248  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "249  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "250  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "\n",
       "[251 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = esm_tools.alphabet.to_dict()\n",
    "\n",
    "encodings = {}\n",
    "for key, value in msa_results.items():\n",
    "    sequences = value[1]\n",
    "    e = torch_tools.one_hot_encoder(sequences, alphabet)\n",
    "    encoded_sequences = [encoding for encoding in e]\n",
    "    encodings[key] = pd.DataFrame({\n",
    "        'label':value[0], \n",
    "        'x':encoded_sequences\n",
    "    })\n",
    "\n",
    "encodings['MSH2_HUMAN.fasta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6634edc-c867-46ce-9cfe-8bdaffa009ab",
   "metadata": {},
   "source": [
    "## Bayesian VAE\n",
    "---\n",
    "below I build a simple prototype of a bayesian VAE for all the proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca70259-a570-431d-bf18-31ef782bd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, z_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        last_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            linear_layer = nn.Linear(last_dim, hidden_dim)\n",
    "            nn.init.kaiming_normal_(linear_layer.weight)\n",
    "            self.layers.append(linear_layer)\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            last_dim = hidden_dim\n",
    "        self.mu = nn.Linear(last_dim, z_dim)\n",
    "        nn.init.kaiming_normal_(self.mu.weight)\n",
    "        self.var = nn.Linear(last_dim, z_dim)\n",
    "        nn.init.kaiming_normal_(self.var.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        z_mu = self.mu(x)\n",
    "        z_var = self.var(x)\n",
    "        return z_mu, z_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dims, output_dim, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        last_dim = z_dim\n",
    "        for hidden_dim in reversed(hidden_dims):\n",
    "            linear_layer = nn.Linear(last_dim, hidden_dim)\n",
    "            nn.init.kaiming_normal_(linear_layer.weight)\n",
    "            self.layers.append(linear_layer)\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            last_dim = hidden_dim\n",
    "        self.out = nn.Linear(last_dim, output_dim)\n",
    "        nn.init.kaiming_normal_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        predicted = torch.sigmoid(self.out(x))\n",
    "        return predicted\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, z_dim, dropout=0.0):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dims, z_dim, dropout)\n",
    "        self.decoder = Decoder(z_dim, hidden_dims, input_dim, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mu, z_var = self.encoder(x)\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "        predicted = self.decoder(x_sample)\n",
    "        return predicted, z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c97829-2165-45ae-a852-5f128f47b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.data['label'].iloc[index]\n",
    "        x = self.data['x'].iloc[index]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7389be41-0ac4-4a7c-98e6-967d8d9cc17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "datasets = []\n",
    "for key in encodings.keys():\n",
    "    names.append(str(key)[:-6])\n",
    "    datasets.append(CustomDataset(encodings[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db7bf94-b496-47e4-b33c-8bf529da551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(train_data, val_data, model, optimizer, criterion, scheduler, epochs, device, model_name, verbose=False):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    pbar = tqdm(range(epochs), desc='Training')\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        num_examples = 0\n",
    "        for batch in train_data:\n",
    "            # Move the batch tensors to the right device\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.view(batch.size(0), -1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            recon, mu, logvar = model(batch)\n",
    "            \n",
    "            loss = criterion(recon, batch, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            num_examples += batch.size(0)\n",
    "            \n",
    "        average_train_loss = train_loss / num_examples\n",
    "        train_losses.append(average_train_loss)\n",
    "    \n",
    "        if epoch % 100 == 0:\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}, Train Loss: {average_train_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            num_examples = 0\n",
    "            for batch in val_data:\n",
    "                 # flatten the batch\n",
    "                batch = batch.view(batch.size(0), -1)\n",
    "                batch = batch.to(device)\n",
    "                recon, mu, logvar = model(batch)\n",
    "                loss = criterion(recon, batch, mu, logvar)\n",
    "                val_loss += loss.item()\n",
    "                num_examples += batch.size(0)\n",
    "\n",
    "            average_val_loss = val_loss / num_examples\n",
    "            val_losses.append(average_val_loss)\n",
    "            if epoch % 100 == 0:\n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch+1}, Val Loss: {average_val_loss:.4f}\")\n",
    "                    \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix({'Train Loss': average_train_loss, 'Val Loss': average_val_loss, 'LR': current_lr})\n",
    "\n",
    "        # Save model if it's the best so far\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            torch.save(model.state_dict(), f'../checkpoints/{model_name}.pt')\n",
    "            if verbose:\n",
    "                print(f\"Model saved at epoch {epoch+1}, Val Loss: {average_val_loss:.4f}\")\n",
    "            best_epoch = epoch\n",
    "    \n",
    "        scheduler.step()\n",
    "        \n",
    "    plot_losses(train_losses, val_losses, best_epoch, fname=model_name+'.png')\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_losses(train_losses, val_losses, best_epoch, fname=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.axvline(x=best_epoch, color='r', linestyle='--', label='Best Model')\n",
    "    plt.title('Train and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    if fname is not None:\n",
    "        plt.savefig(fname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d36f14d-0fdd-45e5-b726-b5ea353274d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d5f02f5-8cb0-4b60-8a7a-a015bce022f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baed2125-bf1b-4248-916d-9336701c79e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSH2_HUMAN_VAE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█████████▌                                                                             | 22/200 [00:27<03:44,  1.26s/it, Train Loss=330, Val Loss=374, LR=0.001]\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model on the dataset\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m, in \u001b[0;36mtrain_vae\u001b[0;34m(train_data, val_data, model, optimizer, criterion, scheduler, epochs, device, model_name, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(recon, batch, mu, logvar)\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m num_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/proteusAI/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/proteusAI/lib/python3.8/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/proteusAI/lib/python3.8/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniforge3/envs/proteusAI/lib/python3.8/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/proteusAI/lib/python3.8/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/proteusAI/lib/python3.8/site-packages/torch/optim/adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    360\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    364\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 2**10\n",
    "\n",
    "for i, dat in enumerate(datasets):\n",
    "    # define model name for saving\n",
    "    model_name = names[i] + '_VAE'\n",
    "    \n",
    "    # Split the dataset into training and validation sets\n",
    "    train_size = int(0.8 * len(dat))  # 80% for training\n",
    "    val_size = len(dat) - train_size\n",
    "    train_dataset, val_dataset = random_split(dat, [train_size, val_size])\n",
    "    \n",
    "    train_data = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_data = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Assuming each sequence in the dataset is one-hot encoded and is of shape (seq_len, alphabet_size)\n",
    "    seq_len, alphabet_size = train_data.dataset[0].shape\n",
    "    \n",
    "    # Initialize model, optimizer and epochs\n",
    "    model = VAE(input_dim=seq_len * alphabet_size, hidden_dims=[2048, 1024, 256], z_dim=64, dropout=0.1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    epochs = 200\n",
    "    \n",
    "    # Train the model on the dataset\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    model = train_vae(train_data, val_data, model, optimizer, criterion, scheduler, epochs, device, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277042f-2ccd-495e-8e41-3aaf1258a17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
